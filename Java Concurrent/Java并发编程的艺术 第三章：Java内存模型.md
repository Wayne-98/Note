---
title: Java并发编程的艺术 第三章：Java内存模型
date: {date}
tags: Java
categories: Java Concurrent
---
# 3. Java内存模型

Java线程之间的通信对程序员完全透明，内存可见性问题很容易困扰Java程序员。

* Java内存模型的基础：主要介绍内存模型相关的基本概念；
* Java内存模型中的顺序一致性：主要介绍重排序与顺序一致性内存模型；
* 同步原语：主要介绍3个同步原语（synchronized、volatile和final）的内存语义及重排序规则在处理器
  中的实现；
* Java内存模型的设计：主要介绍Java内存模型的设计原理，及其与处理器内存模型和顺序一致性内存模型的关系。

## 3.1 Java内存模型的基础
### 3.1.1 并发编程模型的两个关键问题
1. **线程之间的通信**  
    * 共享内存
    * 消息传递
2. **线程之间的同步**
    * 在共享内存并发模型中，同步是显示进行的
    * 在消息传递并发模型中，由于消息的发送必须在消息的接收之前，同步是隐式进行
***
### 3.1.2 Java内存模型的抽象结构

实例域，静态域和数组存储在堆内存中，多线程共享（共享变量）。
局部变量，方法定义参数和异常处理器参数不在线程之间共享，所以不会有内存可见性问题，也不受内存模型的影响。

**Java线程之间的通信由Java内存模型JMM控制, JMM决定一个线程对共享变量的写入何时对另一个线程可见**

* JMM定义了线程和主内存之间的抽象关系
    线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。
  * 本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化

* JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。
***
### 3.1.3 从源代码到指令序列的重排序
1. **编译器优化的重排序**
编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
2. **指令级并行的重排序**
现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. **内存系统的重排序**
由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过**内存屏障指令**来禁止特定类型的处理器重排序。

### 3.1.4 并发编程模型的分类

现代处理器使用写缓冲区临时保存向内存写入的数据。

优点：

* 保证指令流水线式持续运行，避免由于处理器停顿等待向内存写入数据而产生的延迟。

* 通过批处理的方式刷新写缓冲区，以及合并写缓冲区对同一内存地址的多次写，可以减少对内存总线的占用

缺点：

* 每个处理器上的写缓冲区仅仅对其自己可见，处理器对内存的读写操作的执行顺序，并不一定与内存实际发生的读写顺序一致。



为了保证内存可见性，Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。

| 屏障类型            | 指令示例                     | 说明                                                         |
| :------------------ | ---------------------------- | ------------------------------------------------------------ |
| LoadLoad Barriers   | Load 1; LoadLoad; Load 2     | 确保Load 1 数据的装载先于 <br/>Load 2 及后续所有装载指令的装载 |
| StoreStore Barriers | Store 1; StoreStore; Store 2 | 确保 Store1 的数据对其他处理器可见<br/>(刷新到内存)先于 Store2 及后续存储指令的存储 |
| LoadStore Barriers  | Load 1; LoadStore; Store 2   | 确保Load 1 数据的装载先于 <br/>Store 2 及后续的存储指令刷新到内存 |
| StoreLoad Barriers  | Store 1; StoreLoad; Load 2   | 确保 Store1 的数据对其他处理器可见<br/>(刷新到内存)先于 Load 2 及后续装载指令的装载。 |

StoreLoad Barriers 是一个“全能型” 的屏障，执行该屏障开销大，因为当前处理器会把写缓冲区中的数据全部刷新到内存中。

***
### 3.1.5 happens-before简介

在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关
系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。

* the first is visible to and ordered before the second
* 一个happens-before规则对应于一个或多个编译器和处理器重排序规则

1. **程序顺序规则**
 一个线程中的每个操作，happens-before于线程中的任意后续操作
2. **监视器锁规则**
对一个锁的解锁，happens-before于随后对这个锁的加锁
3. **volatile变量规则**
对一个volatile域的写，happens-before于任意后续对这个volatile域的读
4. **传递性**
***

## 3.2 重排序

重排序是指编译器和处理器为了优化程序性能而对**指令序列进行重新排序**的一种手段。

### 3.2.1 数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性

编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。

### 3.2.2 as-if-serial 语义

as-if-serial 语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime 和处理器都必须遵守 as-if-serial 语义。



as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。

### 3.2.3 程序顺序规则

在不改变程序执行结果的前提下，尽可能提高并行度。

### 3.2.4 重排序对多线程的影响

代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条
件判断为真时，就把该计算结果写入变量i中。



## 3.3 顺序一致性

顺序一致性内存模型是一个理论参考模型。

### 3.3.1 数据竞争和顺序一致性

